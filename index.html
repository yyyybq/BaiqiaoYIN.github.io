<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Baiqiao Yin</title>

    <meta name="author" content="Baiqiao Yin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Baiqiao Yin„ÄåÂ∞πÊüè‰πî„Äç
                  </p>
                  <p>
                    Hi there! I'm Baiqiao Yin. Now I'm a research intern at Northwestern University, very fortunate to work with <a href="https://limanling.github.io/">Manling Li</a>.
                     <!-- and collaborate with <a href="https://svl.stanford.edu/">Stanford SVL</a>. -->
                    Previously, I got my B.Eng. in Intelligent Science and Technology from Sun Yat-sen University, where I worked closely with <a href="https://www.cs.cmu.edu/~xiaodan1/">Xiaodan Liang</a>.<br>

                    In the near future, I'll go to New York University to serve as a research assistant in my gap year, working closely with <a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a>.<br>

                    ‚≠êI am open for discussions and looking for PhD opportunities (26 Fall). If you think there is anything interesting we can discuss, feel free to <a href="mailto:yinbaiqiao9@gmail.com">email</a> me!
                  </p>
                  <p style="text-align:center">
                    <a href="yinbaiqiao9@gmail.com">Email</a> /
                    <a href="https://scholar.google.com/citations?user=p8ZtdScAAAAJ&hl">Scholar</a> /
                    <a href="https://github.com/yyyybq/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%; width:37%; max-width:37%;">
                        <a href="images/baiqiao.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/baiqiao.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <h2>Internships</h2>
                  <ul style="list-style-type: none; padding-left: 0;">
                    <li>2024.07 - 2024.11, Shanghai AI Lab, Embodied AI Group. Mentor: <a href="https://sheldontsui.github.io/">Xudong Xu</a></li>
                    <li>2023.05 - 2024.04, Peking  University(SZ), HRI Lab. Mentor: <a href="https://www.ece.pku.edu.cn/info/1046/2596.htm">Mengyuan Liu</a></li>
                  </ul>
                </td>
              </tr>
              <tr>

                <td style="padding-top: 16px;">

                  <h2>üìùResearches</h2>

                  <p>

                  üí¨My research interests lie in spatial intelligence. Currently, my focus is on designing spatial intelligence agents with the following capabilities:

                  </p>

                  <ol>

                  <li>Spatial perception: MLLMs or Large spatial model?</li>

                  <li>Active spatial interaction mechanisms, encompassing environment manipulation and viewpoint optimization</li>

                  <li>Dynamic spatio-temporal understanding for predictive spatial modeling</li>

                  </ol>

                </td>

              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()" bgcolor="#ffffd0">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <img src='images/MindCube.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://mind-cube.github.io/">
                    <span class="papertitle">Spatial Mental Modeling from Limited Views</span>
                  </a>
                  <br>
                  <strong>Baiqiao Yin*</strong>,
                  <a href="https://szymanowiczs.github.io/">Qineng Wang*</a>,
                  <a href="https://williamzhangsjtu.github.io/">Pingyue Zhang</a>,
                  <a href="https://sterzhang.github.io/">Jianshu Zhang</a>,
                  <a href="https://jameskrw.github.io/">Kangrui Wang</a>,
                  <a href="https://zihanwang314.github.io/">Zihan Wang</a>,
                  <a href="https://jieyuz2.github.io/">Jieyu Zhang</a>,
                  <a href="https://keshik6.github.io/">Keshigeyan Chandrasegaran</a>,
                  <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/liu-han.html">Han Liu</a>,
                  <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a>,
                  <a href="https://www.sainingxie.com/">Saining Xie</a>,
                  <a href="https://limanling.github.io/">Manling Li</a>,
                  <a href="https://jiajunwu.com/">Jiajun Wu</a>,
                  <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>
                  <br>
                  <em>arXiv</em>, 2025
                  <br>
                  <a href="https://mind-cube.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/pdf/2506.21458">arXiv</a>
                  <p></p>
                  <p>
                    Key Takeaway: Guiding VLMs to first generate cognitive maps, then reason upon them, is an effective approach to approximate spatial mental modeling with limited views.
                  </p>
                </td>
              </tr>

              <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <img src='images/skeleton2point.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://yyyybq.github.io/Skeleton2Point.github.io/">
                    <span class="papertitle">Skeleton2Point: Recognizing Skeleton-Based Actions as Point Clouds</span>
                  </a>
                  <br>
                  <strong>Baiqiao Yin</strong>,
                  Jiaying Lin</a>,
                  Jiajun Wen</a>,
                  Yue Li</a>,
                  <a href="https://github.com/liujf69">Jinfu Liu</a>,
                  Yanfei Wang</a>,
                  <a href="https://www.ece.pku.edu.cn/info/1046/2596.htm">Mengyuan Liu</a>
                  <br>
                  <em>IROS</em>, 2025 <font color=#FF8080></font>
                  <br>
                  <a href="https://yyyybq.github.io/Skeleton2Point.github.io/">project page</a>
                  /
                  <a href="https://github.com/yyyybq/Skeleton2Point/blob/main/Skeleton2Point.pdf">paper</a>
                  <p></p>
                  <p>
                    Regard skeleton joints as point cloud via incorporating the position information of skeletons into point cloud methods, demonstrating the validity of modeling position relationships with 3D coordinates.
                  </p>
                </td>
              </tr>

              <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Theater.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://howe140.github.io/theatergen.io/">
                    <span class="papertitle">TheaterGen: Character Management with LLM for Consistent Multi-turn Image Generation</span>
                  </a>
                  <br>
                  <a href="https://donahowe.github.io/"></a>Junhao Cheng</a>,
                  <strong>Baiqiao Yin</strong>,
                  Kaixin Cai</a>,
                  Minbin Huang</a>,
                  <a href="https://sysu-hcp.net/faculty/418.html">Hanhui Li</a>,
                  Yuxin He</a>,
                  Xi Lu</a>,
                  Yue Li</a>,
                  Yifei Li</a>,
                  Yiqiang Yan</a>,
                  <a href="https://www.cs.cmu.edu/~xiaodan1/">Xiaodan Liang/a>
                  <br>
                  <em>arrxiv</em>, 2024 <font color=#FF8080></font>
                  <br>
                  <a href="https://howe140.github.io/theatergen.io/">project page</a>
                  /
                  <a href="https://arxiv.org/pdf/2404.18919">arxiv</a>
                  <p></p>
                  <p>
                    Theatergen can interact with users to consistently generate images over multiple Turns.
                  </p>
                </td>
              </tr>

                            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <img src='images/HDBN.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://github.com/liujf69/ICMEW2024-Track10">
                    <span class="papertitle">HDBN: A Novel Hybrid Dual-branch Network for Robust Skeleton-based Action Recognition</span>
                  </a>
                  <br>
                  <a href="https://github.com/liujf69">Jinfu Liu*</a>,
                  <strong>Baiqiao Yin*</strong>,
                  Jiaying Lin</a>,
                  Jiajun Wen</a>,
                  Yue Li</a>,
                  <a href="https://www.ece.pku.edu.cn/info/1046/2596.htm">Mengyuan Liu</a>
                  <br>
                  <em>ICMEW</em>, 2024 <font color=#FF8080></font>
                  <br>
                  <a href="https://github.com/liujf69/ICMEW2024-Track10">code</a>
                  /
                  <a href="https://ieeexplore.ieee.org/document/10645450">paper</a>
                  <p></p>
                  <p>
                    Benefits from the graph convolutional network's proficiency in handling graph-structured data and the powerful modeling capabilities of Transformers for global information.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
            </tbody>
          </table>

          <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <h2>üèÜHonors and Awards</h2>
                  <ul style="list-style-type: none; padding-left: 0;">
                    <li>2024.04: Champion of ICME Grand Challenge Multi-Modal Video Reasoning and Analyzing Competition.</li>
                    <li>2023.10: The Second Prize of Intelligent Robot Fighting and gaming competition.</li>
                    <li>2023.10: Academic Competition Scholarship of Sun Yat-sen University.</li>
                    <li>2023.10: The Third Prize Scholarship of Sun Yat-sen University.</li>
                    <li>2022.10: Academic Competition Scholarship of Sun Yat-sen University.</li>
                    <li>2022.10: The Third Prize Scholarship of Sun Yat-sen University.</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
</body>